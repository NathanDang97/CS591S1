{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CS591S1 - Differential Privacy - Spring 2021\n",
    "\n",
    "## Assignment 2\n",
    "\n",
    "This notebook provides the solution to Exercise 2 of Assignment #2. This includes the algorithms for the Report Noisy Max version of the Median Algorithm and 3 tables recording some statistics of the experiment on each of the 3 settings."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Importing some useful libraries."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from numpy import linalg as LA\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method initialising the dataset for a corresponding setting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init(n, R, setting, k):\n",
    "    li = []\n",
    "    for i in range(n):\n",
    "        if setting == 1:\n",
    "            li.append(np.random.normal(R/4, (R*R)/10))\n",
    "        elif setting == 2:\n",
    "            li.append(np.random.poisson(50))\n",
    "        elif setting == 3:\n",
    "            li.append(np.random.uniform((R/2 - k), (R/2 + k)))\n",
    "    return np.array(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method that rounds the data values to the nearest integer in {1,...,R}."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def round_to_nearest(x, R):\n",
    "    li = []\n",
    "    for i in range(len(x)):\n",
    "        if x[i] <= 0:\n",
    "            li.append(1)\n",
    "        elif x[i] > R:\n",
    "            li.append(R)\n",
    "        else:\n",
    "            li.append(round(x[i]))\n",
    "    return np.array(li)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for determining the rank of y in sorted x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# determine the position of y if it is inserted into the data array x\n",
    "def rank(y, x):\n",
    "    # using the idea of binary search for speed\n",
    "    left = 0\n",
    "    right = len(x)\n",
    "    mid = 0\n",
    "    \n",
    "    while (left < right):\n",
    "        mid = (right + left)//2\n",
    "  \n",
    "        # Check if key is present in array\n",
    "        if (x[mid] == y):\n",
    "            # If duplicates are present, consider the position of last duplicate\n",
    "            while (mid + 1 < len(x) and x[mid + 1] == y):\n",
    "                 mid += 1 # make the rank be the position of last duplicate + 1\n",
    "            break\n",
    "         \n",
    "        # If key is smaller, ignore right half\n",
    "        elif (x[mid] > y):\n",
    "            right = mid\n",
    "  \n",
    "        # If key is greater, ignore left half\n",
    "        else:\n",
    "            left = mid + 1\n",
    "      \n",
    "    # If key is not found in array then it will be before mid\n",
    "    while (mid > -1 and  x[mid] > y):\n",
    "        mid-= 1\n",
    "  \n",
    "    return mid + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    }
   ],
   "source": [
    "# an example\n",
    "x = [1, 2, 3, 5, 6]\n",
    "print(rank(5, x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the sign and score functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sign(z):\n",
    "    if z > 0:\n",
    "        return 1\n",
    "    elif z < 0:\n",
    "        return -1\n",
    "    else:\n",
    "        return 0\n",
    "\n",
    "def score_func(y, x): # with the assumption that x is sorted and entries are unique\n",
    "    rank_y = rank(y, x)\n",
    "    n = len(x)\n",
    "    abs_q = 2*(abs(rank_y - n/2)) # from problem 1b\n",
    "    return -abs_q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Implementing the Report Noisy Max Algorithm."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def rnm_median(x, R, epsilon):\n",
    "    li = []\n",
    "    for y in range(1, R+1):\n",
    "        Z_y = np.random.exponential(2/epsilon)\n",
    "        q = score_func(y, x)\n",
    "        noisy_q = q + Z_y\n",
    "        li.append(noisy_q)\n",
    "    return li.index(max(li)) + 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for running the experiment on the first two settings of Normal and Poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment(setting, n_list, R_list):\n",
    "    output_data = [] # the 2D array that stores the record of each dataset\n",
    "    table_data = [] # the 2D array that stores the entries of the table\n",
    "    for n in n_list:\n",
    "        for R in R_list:\n",
    "            for i in range(0, 50): # running the experiment on each dataset\n",
    "                x = init(n, R, setting, 0)\n",
    "                rounded_x = round_to_nearest(x, R)\n",
    "                rounded_sorted_x = np.sort(rounded_x)\n",
    "                datum = [] # storing the values of the 10 runs\n",
    "                for j in range(0, 10):\n",
    "                    y_hat = rnm_median(rounded_sorted_x, R, 0.1)\n",
    "                    datum.append(abs(n/2 - rank(y_hat, rounded_sorted_x)))\n",
    "                output_data.append(datum)\n",
    "            \n",
    "            # adding entries to the table\n",
    "            table_datum = [] # storing one row of the table\n",
    "            flatten_data = np.array(output_data).flatten()\n",
    "            table_datum.append(np.mean(flatten_data))\n",
    "            table_datum.append(np.std(flatten_data))\n",
    "            \n",
    "            # storing the std of each dataset for averaging later\n",
    "            stds = [] \n",
    "            for k in range(len(output_data)):\n",
    "                stds.append(np.std(output_data[k]))\n",
    "            table_datum.append(np.mean(stds))\n",
    "            table_data.append(table_datum)\n",
    "            table_datum = []\n",
    "            output_data = []\n",
    "            \n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting on the first setting of Normal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Avg error  Std of error  Std among runs\n",
      "n = 50, R = 100           2.628      2.169243        0.616652\n",
      "n = 50, R = 1000          3.070      2.266517        0.078963\n",
      "n = 50, R = 10000         3.060      2.023957        0.000000\n",
      "n = 100, R = 100          3.188      2.364034        1.067336\n",
      "n = 100, R = 1000         3.096      2.784741        0.130360\n",
      "n = 100, R = 10000        4.516      3.132690        0.019165\n",
      "n = 500, R = 100          8.264      6.409236        4.231917\n",
      "n = 500, R = 1000         9.204      6.654501        0.554734\n",
      "n = 500, R = 10000       10.678      6.841514        0.069192\n",
      "n = 2000, R = 100        11.028     11.552974        7.570988\n",
      "n = 2000, R = 1000       17.506     14.041580        1.945152\n",
      "n = 2000, R = 10000      16.334     12.923716        0.208978\n",
      "n = 10000, R = 100       10.296     10.553122        8.998094\n",
      "n = 10000, R = 1000      32.286     29.647938        6.705149\n",
      "n = 10000, R = 10000     38.040     32.274609        1.139831\n"
     ]
    }
   ],
   "source": [
    "n_list = [50, 100, 500, 2000, 10000]\n",
    "R_list = [100, 1000, 10000]\n",
    "data_s1 = experiment(1, n_list, R_list)\n",
    "df_s1 = pd.DataFrame(np.array(data_s1), \n",
    "                     columns = ['Avg error', 'Std of error', 'Std among runs'],\n",
    "                     index = ['n = 50, R = 100', 'n = 50, R = 1000', 'n = 50, R = 10000',\n",
    "                              'n = 100, R = 100', 'n = 100, R = 1000', 'n = 100, R = 10000',\n",
    "                              'n = 500, R = 100', 'n = 500, R = 1000', 'n = 500, R = 10000',\n",
    "                              'n = 2000, R = 100', 'n = 2000, R = 1000', 'n = 2000, R = 10000',\n",
    "                              'n = 10000, R = 100', 'n = 10000, R = 1000', 'n = 10000, R = 10000'])\n",
    "print(df_s1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting on the second setting of Poisson distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                      Avg error  Std of error  Std among runs\n",
      "n = 50, R = 100          16.054      9.429055        8.681054\n",
      "n = 50, R = 1000         23.534      4.913740        3.294764\n",
      "n = 50, R = 10000        24.812      1.903853        0.564000\n",
      "n = 100, R = 100         13.870     14.980290       13.624419\n",
      "n = 100, R = 1000        35.876     19.599302       17.917115\n",
      "n = 100, R = 10000       48.090      8.412960        4.732501\n",
      "n = 500, R = 100         10.146      8.542405        6.191452\n",
      "n = 500, R = 1000        10.386      8.785272        5.867866\n",
      "n = 500, R = 10000        8.768      7.774714        5.521747\n",
      "n = 2000, R = 100        35.178     16.001947        1.023733\n",
      "n = 2000, R = 1000       29.842     18.430655        1.280529\n",
      "n = 2000, R = 10000      35.354     14.048369        1.346605\n",
      "n = 10000, R = 100      188.564     46.779204        0.088000\n",
      "n = 10000, R = 1000     191.622     47.673673        0.064156\n",
      "n = 10000, R = 10000    190.542     53.812454        0.398000\n"
     ]
    }
   ],
   "source": [
    "n_list = [50, 100, 500, 2000, 10000]\n",
    "R_list = [100, 1000, 10000]\n",
    "data_s2 = experiment(2, n_list, R_list)\n",
    "df_s2 = pd.DataFrame(np.array(data_s2), \n",
    "                     columns = ['Avg error', 'Std of error', 'Std among runs'],\n",
    "                     index = ['n = 50, R = 100', 'n = 50, R = 1000', 'n = 50, R = 10000',\n",
    "                              'n = 100, R = 100', 'n = 100, R = 1000', 'n = 100, R = 10000',\n",
    "                              'n = 500, R = 100', 'n = 500, R = 1000', 'n = 500, R = 10000',\n",
    "                              'n = 2000, R = 100', 'n = 2000, R = 1000', 'n = 2000, R = 10000',\n",
    "                              'n = 10000, R = 100', 'n = 10000, R = 1000', 'n = 10000, R = 10000'])\n",
    "print(df_s2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Method for running the experiment of the last setting. Pretty much the same as the previous experiment with a couple slight changes in values to reflect the Bimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def experiment_setting3(setting, n_list, k_list):\n",
    "    output_data = [] # the 2D array that stores the record of each dataset\n",
    "    table_data = [] # the 2D array that stores the entries of the table\n",
    "    for n in n_list:\n",
    "        for k in k_list:\n",
    "            for i in range(0, 50): # running the experiment on each dataset\n",
    "                x = init(n, 1000, setting, k)\n",
    "                rounded_x = round_to_nearest(x, 1000)\n",
    "                rounded_sorted_x = np.sort(rounded_x)\n",
    "                datum = [] # storing the values of the 10 runs\n",
    "                for j in range(0, 10):\n",
    "                    y_hat = rnm_median(rounded_sorted_x, 1000, 0.1)\n",
    "                    datum.append(abs(n/2 - rank(y_hat, rounded_sorted_x)))\n",
    "                output_data.append(datum)\n",
    "            \n",
    "            # adding entries to the table\n",
    "            table_datum = [] # storing one row of the table\n",
    "            flatten_data = np.array(output_data).flatten()\n",
    "            table_datum.append(np.mean(flatten_data))\n",
    "            table_datum.append(np.std(flatten_data))\n",
    "            \n",
    "            # storing the std of each dataset for averaging later\n",
    "            stds = [] \n",
    "            for u in range(len(output_data)):\n",
    "                stds.append(np.std(output_data[u]))\n",
    "            table_datum.append(np.mean(stds))\n",
    "            table_data.append(table_datum)\n",
    "            table_datum = []\n",
    "            output_data = []\n",
    "            \n",
    "    return table_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Experimenting on the third setting of Bimodal distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                    Avg error  Std of error  Std among runs\n",
      "n = 50, k = 10         23.414      5.349636        3.756767\n",
      "n = 50, k = 100        15.642      9.890897        9.128069\n",
      "n = 50, k = 200        11.808      9.091267        8.564808\n",
      "n = 100, k = 10        34.230     20.344559       18.728326\n",
      "n = 100, k = 100       13.446     15.368509       14.097856\n",
      "n = 100, k = 200       12.892     13.459433       12.274292\n",
      "n = 500, k = 10         9.660      8.758790        5.168614\n",
      "n = 500, k = 100        9.846     10.211282        8.994180\n",
      "n = 500, k = 200        9.984     10.635212        9.157683\n",
      "n = 2000, k = 10       34.372     13.569732        2.052767\n",
      "n = 2000, k = 100       8.440      9.395233        7.694983\n",
      "n = 2000, k = 200       9.910      9.690712        8.674274\n",
      "n = 10000, k = 10     204.852     36.755219        0.769329\n",
      "n = 10000, k = 100     14.766     10.733836        4.406293\n",
      "n = 10000, k = 200      9.394      8.578273        5.831657\n"
     ]
    }
   ],
   "source": [
    "n_list = [50, 100, 500, 2000, 10000]\n",
    "k_list = [10, 100, 200]\n",
    "data_s3 = experiment_setting3(3, n_list, k_list)\n",
    "df_s3 = pd.DataFrame(np.array(data_s3), \n",
    "                     columns = ['Avg error', 'Std of error', 'Std among runs'],\n",
    "                     index = ['n = 50, k = 10', 'n = 50, k = 100', 'n = 50, k = 200',\n",
    "                              'n = 100, k = 10', 'n = 100, k = 100', 'n = 100, k = 200',\n",
    "                              'n = 500, k = 10', 'n = 500, k = 100', 'n = 500, k = 200',\n",
    "                              'n = 2000, k = 10', 'n = 2000, k = 100', 'n = 2000, k = 200',\n",
    "                              'n = 10000, k = 10', 'n = 10000, k = 100', 'n = 10000, k = 200'])\n",
    "print(df_s3)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
